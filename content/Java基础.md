   ### 1. wait, sleep区别

1. `wait()`方法属于java.lang.Object, `sleep()`属于java.lang.Thread
2. `wait()`表示等待在一个对象上线,需要获得这个对象的锁,否则抛出`IllegalMonitorStateException`
3. 调用 `wait()`会自动释放获取到的锁,`sleep()`方法不会
4. 线程状态:`wait()`的线程状态为 WAITING,`sleep()` 为TIMED_WAITING



### 2. wait, sleep 区别,调用 wait 方法后,如何唤醒线程

1. 区别略
2. 如何唤醒调用 `wait()`方法的线程
   1.  `wait()`的原理:这个方法需要获取对象的锁, 及`ObjectMonitor` 对象, 这个对象中维护了`_WaitSet` 和`_EntryList`, `wait()`方法就是把当前线程放入`_ WaitSet` 队列中, 再调用` park()`, 挂起当前线程. 最后释放这个锁
   2. 如何唤醒:就是在该对象上调用` notify()` 方法,该方法会在`_ WaitSet` 中随机选取一个线程 放入`_ EntryList` 中,就唤醒了这个线程



### 3. volatile关键字怎么保证可见性

#### 3.1 明确什么是可见性

可见性是指对一个在堆上的变量的修改,每个线程都能看到这个变量的最新的值.

#### 3.2 为什么会出现可见性问题

java 因为跨平台,抽象了一套属于自己的内存模型.存在一个主内存和每个线程都拥有的本地内存.

程序是不能直接访问主内存的,对一个变量的修改,需要将其copy 到本地内存,再修改后刷新会主内存,才完成了对这个变量的修改.如果此时一个线程对变量进行了修改,另外一个线程是看不见这个修改的

#### 3.3 如何保证

volatile 修饰的变量,会建立一个 happen-before 关系.及对于一个 volatile 变量的写 hb 与一个 volatile 变量的写.

volatile 是通过插入内存屏障与禁止指令重排序来保证 volatile 变量的可见性的.

读操作之前插入 loadload 屏障,读操作之后插入 loadstore 屏障

写操作之前插入 storestore 屏障,写操作之后插入storeload 屏障

再底层原理,在x86 架构上,编译成的本地代码,对这些变量的操作,会插入一个 lock 指令.涉及到缓存一致性协议了~

### 4. 反射

#### 4.1 反射的作用

1. 可以于运行时加载,探知和使用编译期间完全未知的类
2. 程序在运行状态中, 可以动态加载一个只有名称的类, 对于任意一个已经加载的类,都能够知道这个类的所有属性和方法; 对于任意一个对象,都能调用他的任意一个方法和属性
3. 加载完类之后, 在堆内存中会产生一个Class类型的对象(一个类只有一个Class对象), 这个对象包含了完整的类的结构信息,而且这个Class对象就像一面镜子,透过这个镜子看到类的结构,所以被称之为:反射
4. 每个类被加载进入内存之后,系统就会为该类生成一个对应的java.lang.Class对象,通过该Class对象就可以访问到JVM中的这个类

#### 4.2 获取Class对象的方式
1. 对象的getClass()方法
2. 类的.class(最安全/性能最好)属性
3. 运用Class.forName(String className)动态加载类,className需要是类的全限定名(最常用)

#### 4.3 获取Class中的信息
- 构造器：`Constructor<T> getConstructor(Class<?>... parameterTypes)`
- 方法：`Method getMethod(String name, Class<?>... parameterTypes)`
- 属性：`Field getField(String name)`
- 注解：`<A extends Annotation A getAnnotation(Class<A> annotationClass)`
- 内部类：`Class<?>[] getDeclaredClasses()`
- 外部类：`Class<?> getDeclaringClass()`
- 所实现的接口：`Class<?>[] getInterfaces()`
- 修饰符：`int getModifiers()`

[https://docs.oracle.com/javase/8/docs/api/java/lang/Class.html](https://docs.oracle.com/javase/8/docs/api/java/lang/Class.html "Class使用文档")

#### 4.4 使用Class的反射
1. 创建对象
	1. 使用Class对象的newInstance()方法来创建该Class对象对应类的实例(这种方式要求该Class对象的对应类有默认构造器).
	2. 先使用Class对象获取指定的Constructor对象, 再调用Constructor对象的newInstance()方法来创建该Class对象对应类的实例(通过这种方式可以选择指定的构造器来创建实例).
	3. 场景使用：对象池技术
2. 调用方法
	1. 通过该Class对象的getMethod来获取一个Method数组或Method对象.每个Method对象对应一个方法,在获得Method对象之后,就可以通过调用invoke方法来调用该Method对象对应的方法
	2. 场景使用：属性注入
3. 访问成员变量
	1. 通过Class对象的的getField()方法可以获取该类所包含的全部或指定的成员变量Field,Filed提供了如下两组方法来读取和设置成员变量值
		1. getXxx(Object obj): 获取obj对象的该成员变量的值, 此处的Xxx对应8中基本类型,如果该成员变量的类型是引用类型, 则取消get后面的Xxx;
		2. setXxx(Object obj, Xxx val): 将obj对象的该成员变量值设置成val值.此处的Xxx对应8种基本类型, 如果该成员类型是引用类型, 则取消set后面的Xxx; 
	2. getDeclaredXxx方法可以获取所有的成员变量,无论private/public;
4. 使用反射获取泛型信息
	- ParameterizedType java.util.Set<java.lang.String>
	```
    Field field = Client.class.getDeclaredField("objectMap");
    Type gType = field.getGenericType();
	```
5. 使用反射获取注解信息
	
    
参考文档：[http://www.importnew.com/17616.html](http://www.importnew.com/17616.html "java反射")

### 5. long类型的操作是原子性吗？为什么？

要分情况讨论，对于64位的系统来说是的，对于32位的系统来说不是，为什么呢？

因为对于32位虚拟机来说，每次原子读写是32位的，而long和double则是64位的存储单元，这样会导致一个线程在写时，操作完前32位的原子操作后，轮到B线程读取时，恰好只读取到了后32位的数据，这样可能会读取到一个既非原值又不是线程修改值的变量，它可能是“半个变量”的数值，即64位数据被两个线程分成了两次读取。



### 6. String 为什么 final 修饰

> 也就是问String 这个类为什么要设计成不可变的

1.字符串常量池

- jvm 存在字符串常量池,创建一个字符串,如果常量池中已经存在,会直接返回这个字符串的引用.如果能随意修改String 的值(修改常量池中的字符串),会出现问题.
- 其实大多数情况下相同的字符串变量他们指向的内存地址是相同的，大量使用字符串的情况下，可以节省内存空间，提高效率。但之所以能实现这个特性，String的不可变性是最基本的一个必要条件。要是内存里字符串内容能改来改去，这么做就完全没有意义了。

2.安全性

java 中大量使用String 字符串作为一个参数,比如` Socket socket = new Socket(host, port)`,如果 String 可修改,我们 会认为连接到某台机器,但实际上并没有

3.不可变对象带来的线程安全性

不可变对象天生就是线程安全的,避免锁操作,带来性能上的优势



### 7. java 为什么不支持多继承

多继承会带来菱形问题.存在一个抽象类 A, 有方法` foo()`, B,C 继承 A并且实现了各自的` foo()` 方法.如果允许多继承, D 继承 B,C 两个类,那么此时D 的` foo()` 存在歧义

### 8. 重构

**为什么要重构**

延续软件生命、适应需求变更、加深理解代码、提高自我编程能力

**何时要重构**

- 添加功能时重构
- 修补错误时重构
- 复审代码时重构

**何时不要重构**

- 无法稳定运行直接重写不用重构
- 项目已经接近最后期限，但是你没有足够的时间

**难点**

- 数据库(database)：结构紧密耦合在一起、数据迁移。
- 兼容新旧接口(interface)

**重构方法**

- 重新组织函数
- 在对象之间搬移特性
- 重新组织数据
- 简化函数调用
- 处理概括关系

### 9.类加载过程
#### 为什么要使用类加载器
类加载是在运行期间完成的，会增加性能开销，但提高了灵活性。

#### 类加载机制
##### 定义
jvm把编译后的.Class字节码文件加载到内存中,对数据进行校验--验证解析--初始化形成可以被虚拟机可以直接使用的java类型的过程,就是虚拟机的类加载机制.
##### 过程
类从被加载到虚拟机内存中开始,到卸载出内存为止,生命周期包括:加载,验证,准备,解析,初始化,使用,卸载这几个阶段.其中加载，验证，准备，初始化和卸载这5个阶段的顺序是固定的,但是解析阶段却是不一定的。
1. 加载阶段,主要完成以下工作.
   - 通过全类名获取定义此类的二进制字节流
   - 将字节流所代表的静态存储结构转换为方法区的运行时数据结构
   - 在堆中生成一个代表该类的Class对象,作为方法区这些数据的访问入口
> 说明:在整个类加载的过程中(具体是获取类二进制字节流的阶段),加载阶段是可控性最强的阶段,是因为加载阶段可以使用系统通过的类加载器来完成,也可以使用用户自定义的类加载器来完成,开发人员可通过类加载器控制字节流的获取方式.

2. 验证阶段,这个阶段主要是确保class文件中的字节流符合当前虚拟机的要求,不危害虚拟机.主要包括以下几个过程:
    - 文件格式验证, 验证class文件的格式规范. 
    - 元数据验证,这个阶段是对字节码描述信息进行语义分析,保证信息符合java的语言规范要求. 
    - 字节码校验,这个阶段主要是对类中的方法体进行验证,保证该类中的方法在运行时不会发生危害虚拟机行为.
    - 符号引用验证,这个阶段主要通过字符串描述的全限定名是否能找到对应的类,以及方法字段的访问控制,(private、protected、public、default)是否能被访问.

3. 准备阶段.这个阶段是正式为变量分配内存并且设置变量初始值的阶段,这些内存都在方法区进行分配.
这块有需要注意的地方:此时的内存分配仅仅包括static变量,而不包括实例变量(实例变量会随着对象
的创建在java堆中分配),这时候的初始值一般情况下都是0.或者false。
    
> 例如,有变量public static 
int value = 100;那value在准备阶段之后的值是0而不是100,把value赋值为100是在之后的初始化
阶段.当然这个也不是绝对的,例如常量 public static final int value = 100,因为此时value
是常量,虚拟机在准备阶段的时候就会设置为100.

4. 解析阶段,将常量池中的符号引用转换为直接用的过程.
    - 符号引用：符号引用是一组符号来描述所引用的目标对象，符号可以是任何形式的字面量，只要使用
时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标对象并不一定已经
加载到内存中。
    - 直接引用：直接引用可以是直接指向目标对象的指针、相对偏移量或是一个能间接定位到目标的句柄。
直接引用是与虚拟机内存布局实现相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一
般不会相同，如果有了直接引用，那引用的目标必定已经在内存中存在。

5. 初始化阶段,类的初始化是类加载的最后一步,该过程是根据程序员主观意志去初始化变量.初始化阶
段是执行类构造器<clinit>() 方法的过程.<clinit>方法在以下情况下被执行:
    - 当遇到new,getstatic,putstatic或者invokestatic这四条字节码指令的时候,如果该类没有进行
初始化,则需要先初始化.这四条指令对应的是实例化对象,获取一个静态变量,设置一个静态变量(常量
放在常量池中,不会触发),或者调用静态方法的时候.
    - 当时候反射包的方法对类进行反射调用的时候
    - 当初始化一个类的时候,发现该类的父类还没有进行初始化,则初始其父类
    - 当jvm启动的时候,当用户指定执行一个主类(就是包含main的那个类),虚拟机会先初始化这个类.

### 10. 处理hash冲突的方法
1. 开放定址法
  - 线性探测法
  - 二次探测法
  - 双重散列法（开放定址里面最好）
2. 拉链法：冲突的全部放到一个链表里面
- 拉链法的优点
与开放定址法相比，拉链法有如下几个优点：
①拉链法处理冲突简单，且无堆积现象，即非同义词决不会发生冲突，因此平均查找长度较短；
②由于拉链法中各链表上的结点空间是动态申请的，故它更适合于造表前无法确定表长的情况；
③开放定址法为减少冲突，要求装填因子α较小，故当结点规模较大时会浪费很多空间。而拉链法中可取α≥1，且结点较大时，拉链法中增加的指针域可忽略不计，因此节省空间；
④在用拉链法构造的散列表中，删除结点的操作易于实现。只要简单地删去链表上相应的结点即可。
- 拉链法的缺点
　拉链法的缺点是：指针需要额外的空间，故当结点规模较小时，开放定址法较为节省空间，而若将节省的指针空间用来扩大散列表的规模，可使装填因子变小，这又减少了开放定址法中的冲突，从而提高平均查找速度。
3. 再哈希法：这种方法是同时构造多个不同的哈希函数
4. 建立公共溢出区：这种方法的基本思想是：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表


### 11. 一致性hash
一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：
1. 平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。
2. 单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 
3. 分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。
4. 负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。

再精简一点：
1. 每个地方放一点，利用好空间
2. 增删机器缓冲东西位置不变
3. 相同东西只存一份，大家都看得到
4. 不同用户映射东西应该一样，不然就冲突了 




### 12. 使用LinkedHashMap 实现LRU

总结以下几点：

1 linkedhashmap在hashmap的数组加链表结构的基础上，将所有节点连成了一个双向链表。

2 当主动传入的accessOrder参数为false时, 使用put方法时，新加入元素不会被加入双向链表，get方法使用时也不会把元素放到双向链表尾部。

3 当主动传入的accessOrder参数为true时，使用put方法新加入的元素，如果遇到了哈希冲突，并且对key值相同的元素进行了替换，就会被放在双向链表的尾部，当元素超过上限且removeEldestEntry方法返回true时，直接删除最早元素以便新元素插入。如果没有冲突直接放入，同样加入到链表尾部。使用get方法时会把get到的元素放入双向链表尾部。

4 linkedhashmap的扩容比hashmap来的方便，因为hashmap需要将原来的每个链表的元素分别在新数组进行反向插入链化，而linkedhashmap的元素都连在一个链表上，可以直接迭代然后插入。

5 linkedhashmap的removeEldestEntry方法默认返回false，要实现lru很重要的一点就是集合满时要将最久未访问的元素删除，在linkedhashmap中这个元素就是头指针指向的元素。实现LRU可以直接实现继承linkedhashmap并重写removeEldestEntry方法来设置缓存大小。jdk中实现了LRUCache也可以直接使用。


### 13. hashmap原理


hashmap是一个key-value键值对的数据结构，从结构上来讲在jdk1.8之前是用数组加链表的方式实现，jdk1.8加了红黑树，hashmap数组的默认初始长度是16，hashmap数组只允许一个key为null，允许多个value为null
hashmap的内部实现，hashmap是使用数组+链表+红黑树的形式实现的，其中数组是一个一个Node[]数组，我们叫他hash桶数组，它上面存放的是key-value键值对的节点。HashMap是用hash表来存储的，在hashmap里为解决hash冲突，使用链地址法，简单来说就是数组加链表的形式来解决，当数据被hash后，得到数组下标，把数据放在对应下表的链表中。

然后再说一下hashmap的方法实现

put方法，put方法的第一步，就是计算出要put元素在hash桶数组中的索引位置，得到索引位置需要三步，取得put元素key的hashcode值，高位运算，取模运算，高位运算就是用第一步得到的值h，用h的高16位和低16位进行异或操作，第三步为了使hash桶数组元素分布更均匀，采用取模运算，取模运算就是用第二步得到的值和hash桶数组长度-1的值取与。这样得到的结果和传统取模运算结果一致，而且效率比取模运算高
jdk1.8中put方法的具体步骤，先判断hashmap是否为空，为空的话扩容，不为空计算出key的hash值i，然后看table[i]是否为空，为空就直接插入，不为空判断当前位置的key和table[i]是否相同，相同就覆盖，不相同就查看table[i]是否是红黑树节点，如果是的话就用红黑树直接插入键值对，如果不是开始遍历链表插入，如果遇到重复值就覆盖，否则直接插入，如果链表长度大于8，转为红黑树结构，执行完成后看size是否大于阈值threshold，大于就扩容，否则直接结束

get方法就是计算出要获取元素的hash值，去对应位置取即可。

扩容机制，hashmap的扩容中主要进行两部，第一步把数组长度变为原来的两倍，第二部把旧数组的元素重新计算hash插入到新数组中，在jdk1.8时，不用重新计算hash，只用看看原来的hash值新增的一位是零还是1，如果是1这个元素在新数组中的位置，是原数组的位置加原数组长度，如果是零就插入到原数组中。扩容过程第二部一个非常重要的方法是transfer方法，采用头插法，把旧数组的元素插入到新数组中。

3.hashmap大小为什么是2的幂次方

在计算插入元素在hash桶数组的索引时第三步，为了使元素分布的更加均匀，用取模操作，但是传统取模操作效率低，然后优化成h&(length-1)，设置成2幂次方，是因为2的幂次方-1后的值每一位上都是1，然后与第二步计算出的h值与的时候，最终的结果只和key的hashcode值本身有关，这样不会造成空间浪费并且分布均匀，如果不是2的幂次方
如果length不为2的幂，比如15。那么length-1的2进制就会变成1110。在h为随机数的情况下，和1110做&操作。尾数永远为0。那么0001、1001、1101等尾数为1的位置就永远不可能被entry占用。这样会造成浪费，不随机等问题。


### concurrentHashMap 1.7 和 1.8的区别
jdk 1.8:

判断Node[]数组是否初始化，没有则进行初始化操作
通过hash定位Node[]数组的索引坐标，是否有Node节点，如果没有则使用CAS进行添加（链表的头结点），添加失败则进入下次循环。
检查到内部正在扩容，如果正在扩容，就帮助它一块扩容。
如果f!=null，则使用synchronized锁住f元素（链表/红黑二叉树的头元素）
4.1 如果是Node(链表结构)则执行链表的添加操作。
4.2 如果是TreeNode(树型结果)则执行树添加操作。
判断链表长度已经达到临界值8 就需要把链表转换为树结构。
总结：
    JDK8中的实现也是锁分离的思想，它把锁分的比segment（JDK1.5）更细一些，只要hash不冲突，就不会出现并发获得锁的情况。它首先使用无锁操作CAS插入头结点，如果插入失败，说明已经有别的线程插入头结点了，再次循环进行操作。如果头结点已经存在，则通过synchronized获得头结点锁，进行后续的操作。性能比segment分段锁又再次提升。


JDK1.7：

- jdk1.7中采用Segment + HashEntry的方式进行实现
- ConcurrentHashMap初始化时，计算出Segment数组的大小ssize和每个Segment中HashEntry数组的大小cap，并初始化Segment数组的第一个元素；其中ssize大小为2的幂次方，默认为16，cap大小也是2的幂次方，最小值为2，最终结果根据根据初始化容量initialCapacity进行计算，其中Segment在实现上继承了ReentrantLock，这样就自带了锁的功能。
- 当执行put方法插入数据时，根据key的hash值，在Segment数组中找到相应的位置，如果相应位置的Segment还未初始化，则通过CAS进行赋值，接着执行Segment对象的put方法通过加锁机制插入数据

场景：线程A和线程B同时执行相同Segment对象的put方法

1、线程A执行tryLock()方法成功获取锁，则把HashEntry对象插入到相应的位置；
2、线程B获取锁失败，则执行scanAndLockForPut()方法，在scanAndLockForPut方法中，会通过重复执行tryLock()方法尝试获取锁，在多处理器环境下，重复次数为64，单处理器重复次数为1，当执行tryLock()方法的次数超过上限时，则执行lock()方法挂起线程B；
3、当线程A执行完插入操作时，会通过unlock()方法释放锁，接着唤醒线程B继续执行；
- 因为ConcurrentHashMap是可以并发插入数据的，所以在准确计算元素时存在一定的难度，一般的思路是统计每个Segment对象中的元素个数，然后进行累加，但是这种方式计算出来的结果并不一样的准确的，因为在计算后面几个Segment的元素个数时，已经计算过的Segment同时可能有数据的插入或则删除，在1.7的实现中，采用了如下方式：
先采用不加锁的方式，连续计算元素的个数，最多计算3次：
1、如果前后两次计算结果相同，则说明计算出来的元素个数是准确的；
2、如果前后两次计算结果都不同，则给每个Segment进行加锁，再计算一次元素的个数；


JDK1.8:

- 1.8中放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保证并发安全进行实现
- 只有在执行第一次put方法时才会调用initTable()初始化Node数组
- 当执行put方法插入数据时，根据key的hash值，在Node数组中找到相应的位置

1、如果相应位置的Node还未初始化，则通过CAS插入相应的数据；
2、如果相应位置的Node不为空，且当前该节点不处于移动状态，则对该节点加synchronized锁，如果该节点的hash不小于0，则遍历链表更新节点或插入新节点；
3、如果该节点是TreeBin类型的节点，说明是红黑树结构，则通过putTreeVal方法往红黑树中插入节点；
4、如果binCount不为0，说明put操作对数据产生了影响，如果当前链表的个数达到8个，则通过treeifyBin方法转化为红黑树，如果oldVal不为空，说明是一次更新操作，没有对元素个数产生影响，则直接返回旧值；
5、如果插入的是一个新节点，则执行addCount()方法尝试更新元素个数baseCount；

- 1.8中使用一个volatile类型的变量baseCount记录元素的个数，当插入新数据或则删除数据时，会通过addCount()方法更新baseCount，

1、初始化时counterCells为空，在并发量很高时，如果存在两个线程同时执行CAS修改baseCount值，则失败的线程会继续执行方法体中的逻辑，使用CounterCell记录元素个数的变化；
2、如果CounterCell数组counterCells为空，调用fullAddCount()方法进行初始化，并插入对应的记录数，通过CAS设置cellsBusy字段，只有设置成功的线程才能初始化CounterCell数组
3、如果通过CAS设置cellsBusy字段失败的话，则继续尝试通过CAS修改baseCount字段，如果修改baseCount字段成功的话，就退出循环，否则继续循环插入CounterCell对象；所以在1.8中的size实现比1.7简单多，因为元素个数保存baseCount中，部分元素的变化个数保存在CounterCell数组中。通过累加baseCount和CounterCell数组中的数量，即可得到元素的总个数；


### lock和sychronized 的区别


|类别  |synchronized | Lock|
|存在层次  |Java的关键字，|在jvm层面上  是一个类|
|锁的释放  |1、以获取锁的线程执行完同步代码，释放锁 2、线程执行发生异常，jvm会让线程释放锁 | 在finally中必须释放锁，不然容易造成线程死锁|
|锁的获取  |假设A线程获得锁，B线程等待。如果A线程阻塞，B线程会一直等待 |分情况而定，Lock有多个锁获取的方式，具体下面会说道，大致就是可以尝试获得锁，线程可以不用一直等待|
|锁状态 |无法判断  |可以判断|
|锁类型| 可重入 不可中断 非公平  |可重入 可判断 可公平（两者皆可）|
|性能  |少量同步  |大量同步|

1、线程自旋和适应性自旋 
我们知道，java’线程其实是映射在内核之上的，线程的挂起和恢复会极大的影响开销。并且jdk官方人员发现，很多线程在等待锁的时候，在很短的一段时间就获得了锁，所以它们在线程等待的时候，并不需要把线程挂起，而是让他无目的的循环，一般设置10次。这样就避免了线程切换的开销，极大的提升了性能。 
而适应性自旋，是赋予了自旋一种学习能力，它并不固定自旋10次一下。他可以根据它前面线程的自旋情况，从而调整它的自旋，甚至是不经过自旋而直接挂起。

2、锁消除 
什么叫锁消除呢？就是把不必要的同步在编译阶段进行移除。 
那么有的小伙伴又迷糊了，我自己写的代码我会不知道这里要不要加锁？我加了锁就是表示这边会有同步呀？ 
并不是这样，这里所说的锁消除并不一定指代是你写的代码的锁消除，我打一个比方： 
在jdk1.5以前，我们的String字符串拼接操作其实底层是StringBuffer来实现的（这个大家可以用我前面介绍的方法，写一个简单的demo，然后查看class文件中的字节码指令就清楚了），而在jdk1.5之后，那么是用StringBuilder来拼接的。我们考虑前面的情况，比如如下代码：
```
String str1="qwe";
String str2="asd";
String str3=str1+str2;
```
底层实现会变成这样：
```
StringBuffer sb = new StringBuffer();
sb.append("qwe");
sb.append("asd");
```
我们知道，StringBuffer是一个线程安全的类，也就是说两个append方法都会同步，通过指针逃逸分析（就是变量不会外泄），我们发现在这段代码并不存在线程安全问题，这个时候就会把这个同步锁消除。

3、锁粗化 
在用synchronized的时候，我们都讲究为了避免大开销，尽量同步代码块要小。那么为什么还要加粗呢？ 
我们继续以上面的字符串拼接为例，我们知道在这一段代码中，每一个append都需要同步一次，那么我可以把锁粗化到第一个append和最后一个append（这里不要去纠结前面的锁消除，我只是打个比方）

4、轻量级锁

5、偏向锁






## References

1. [Java集合详解5：深入理解LinkedHashMap和LRU缓存](https://h2pl.github.io/2018/05/11/collection5/)










